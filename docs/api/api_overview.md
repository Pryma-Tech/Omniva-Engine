# Omniva Engine — API Overview

## 1. Purpose of the API
The Omniva Engine API exposes programmatic control over every stage of the content pipeline. Dashboard clients, automation scripts, CLI utilities, and external systems call the API to create projects, manage creators, launch scraping jobs, inspect analysis outputs, trigger editing/uploading, adjust schedules, and retrieve interpretability data. By mirroring the clipfarm lifecycle, the API enables full automation from ingestion through publishing while preserving auditing and governance.

## 2. Architecture
- **Backend**: FastAPI application deployed behind authenticated gateways.
- **Protocol**: REST-style endpoints exchanging JSON payloads over HTTPS.
- **Execution**: API requests mutate state in PostgreSQL (system of record) and enqueue tasks for workers (Scraper, Analyzer, Editor, Uploader, Scheduler).
- **Cognitive Layer**: Worker events and API-triggered operations notify cognitive subsystems (Paradox, Lattice, Pantheon, etc.) through internal buses; results surface back through API responses.

Diagram:
```
(Client / Dashboard / Automation)
        ↓ HTTPS / JSON
        [FastAPI Gateway]
        ↓           ↓
   [Workers & Queues]   [Database + Stardust + Cognitive Subsystems]
```

## 3. API Principles
- **Predictable**: Consistent nouns/verbs, idempotent GET/DELETE, side-effecting POST.
- **Versioned**: All endpoints live under `/v1/`; future major versions use `/v2/`.
- **Typed**: JSON schemas define request/response bodies; enums documented per field.
- **Transparent Errors**: Machine-readable error objects with stable codes.
- **Paginated**: Collection endpoints support `limit`, `offset`, or cursor pagination for large result sets.

## 4. Authentication
- Current deployments run behind the Omniva Dashboard and rely on trusted network access; no external authentication is required.
- Future: API key or OAuth2 client credentials per tenant to enable third-party integrations. Spec should treat `Authorization: Bearer <token>` as forthcoming requirement.

## 5. Response Format
Every endpoint returns a wrapper object:
```json
{
  "status": "success",
  "data": { /* endpoint-specific payload */ },
  "error": null,
  "meta": { "request_id": "uuid", "generated_at": "2024-05-07T15:00:00Z" }
}
```
On error:
```json
{
  "status": "error",
  "data": null,
  "error": { "message": "clip not found", "code": "CLIP_NOT_FOUND" },
  "meta": { "request_id": "uuid" }
}
```

## 6. Error Handling
- HTTP status codes align with behavior: `400 Bad Request`, `401 Unauthorized`, `404 Not Found`, `409 Conflict`, `422 Validation Error`, `500 Internal Server Error`.
- Errors generated by workers propagate back via Eclipse Engine. For example, a failed upload surfaces as `409` with `UPLOAD_FAILED`, while Eclipse schedules a retry.
- All API interactions are logged to Stardust, including request metadata, response code, and associated entity IDs, ensuring interpretability through HaloLux.

## 7. Rate Limits (Future)
- Planned per-project/requester rate limiting with leaky-bucket semantics.
- Queue saturation indicators will be exposed via `Retry-After` headers when downstream workers near capacity.
- Until rate limits ship, monitoring dashboards track usage and operations teams can throttle via infrastructure policies.
